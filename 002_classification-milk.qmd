---
title: "Classification - Milk Quality Prediction"
author: "Muhammad Apriandito"
format: html
editor: visual
---

### Setup

```{r}
# Set Parameter
set.seed(123)
options(scipen = 10000)
```

### Load Packages

```{r}
# Load Packages
library(tidyverse)
library(tidymodels)
library(skimr)
library(janitor)
library(discrim)
library(naivebayes)
library(rpart)
library(rpart.plot)
```

### Load Data

```{r}
# Load Data
df <- read_csv("data/milk.csv")
```

```{r}
# Show Data
df
```

```{r}
# Show Sample Value for Each Variables
glimpse(df)
```

```{r}
# Show Data Summary
skim(df)
```

### Data Preprocessing

```{r}
# Data Preprocessing
df_fix <- df %>%
  mutate_at(c("taste", "odor", "fat", "turbidity", "grade"), as.factor)
```

```{r}
# Show Processed Data
glimpse(df_fix)
```

### Data Exploration

```{r}
# Show Milk Grade Distribution
df_fix %>% 
  group_by(grade) %>%
  count() %>%
  ggplot(aes(x = grade, y = n, fill = grade)) +
  geom_col() +
  theme_minimal()
```

```{r}
# Show Temperature Distribution Distinguished by Grade
df_fix %>% 
  ggplot(aes(x = temprature, fill = grade)) +
  geom_histogram(color = "white") +
  theme_minimal()
```

```{r}
# Show the Relationship Between Temperature, pH, and Grade of Milk
df_fix %>% 
  ggplot(aes(x = temprature, y = ph, color = grade)) +
  geom_point() +
  theme_minimal()
```

### Construct the Classification Model

#### Data Split

```{r}
# Split Data into 70% Training Data and 30% Testing Data 
df_split <- initial_split(df_fix, prop = 0.7)
```

```{r}
# Show Data Proportion
df_split
```

#### Define Data Processing Flow

```{r}
# Define Data Processing Flow
df_recipe <- training(df_split) %>%
  recipe(grade ~ .) 
df_recipe
```

#### Modeling

Check available models at <https://www.tidymodels.org/find/parsnip/>

##### Decision Tree

```{r}
# Define the Machine Learning Algorithm - Decision Tree
dt <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")
```

```{r}
# Create Model Workflow
workflow_dt <- workflow() %>%
  add_model(dt) %>%
  add_recipe(df_recipe)
```

```{r}
# Train Model
model_dt <- fit(workflow_dt, training(df_split))
model_dt
```

```{r}
# Visualize the Decision Tree
tree_fit <- model_dt %>%
  extract_fit_parsnip()
rpart.plot(tree_fit$fit, roundint=FALSE)
```

##### Naive Bayes

```{r}
# Define the Machine Learning Algorithm - Naive Bayes
nb <-  naive_Bayes() %>% 
  set_engine("naivebayes")
```

```{r}
# Create Model Workflow
workflow_nb <- workflow() %>%
  add_model(nb) %>%
  add_recipe(df_recipe)
```

```{r}
# Train Model
model_nb <- fit(workflow_nb, training(df_split))
model_nb
```

#### Model Evaluation

```{r}
# Define Metrics to Evaluate the Model
multi_metrics <- metric_set(accuracy, precision, recall, specificity, f_meas)
```

```{r}
# Measure Model Performance
model_dt %>%
  predict(testing(df_split)) %>%
  bind_cols(testing(df_split)) %>%
  multi_metrics(truth = grade, estimate = .pred_class)
```

```{r}
# Measure Model Performance
model_nb %>%
  predict(testing(df_split)) %>%
  bind_cols(testing(df_split)) %>%
  multi_metrics(truth = grade, estimate = .pred_class)
```

#### Make Prediction

```{r}
# Create a New Data
df_new <- tibble(
  ph = 6.6, 
  temprature = 35, 
  taste = factor(1),
  odor = factor(1), 
  fat = factor(1),
  turbidity = factor(1),
  colour = 246,
  grade = factor("high")
)
```

```{r}
# Predict the New Data
model_nb %>%
  predict(df_new) 
```
